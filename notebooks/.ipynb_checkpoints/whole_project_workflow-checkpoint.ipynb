{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Statistical constraints on observing low-angle normal fault seismicity"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Introduction\n",
      "\n",
      "The recognition of low-angle normal faults, or LANFs, with fault dips <30$^\\circ$ in the geologic record and their hypothesized role in accommodating large-magnitude continental extension [1] has been one of the most important developments in tectonics over the past several decades.\n",
      "However, despite widespread field observations of inactive LANFs[2] and their central role in modern extensional tectonic theory[3], they remain enigmatic and contentious structures. \n",
      "This is for two reasons: because brittle faulting on LANFs is in apparent conflict with standard rock mechanical theory as typically applied to the upper crust [4,5], and because observations of active faulting on LANFs is sparse and at times ambiguous[6,7].\n",
      "A considerable amount of research has been performed to address the former concern, reconciling LANF slip with rock mechanics.\n",
      "The latter issue, the paucity of observations, has inhibited hypothesis testing of LANF fault theory, and has also contributed to a mode of thought where the absence of evidence is taken as evidence of absence [8].\n",
      "Alternately, the lack of observed seismic slip on a continental LANF may be explained by the rarity of seismicity and the small number of potential active structures.\n",
      "In this work, we choose to directly address the question of whether the lack of observed seismicity may be interpreted as an indication that LANFs may not slip seismically, or an effect of a small sample size of LANFs that show typical seismic behavior. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Monte Carlo simulations of earthquake sequences on individual faults\n",
      "\n",
      "In order to robustly determine the probability that an earthquake on any individual LANF will be observed, we create synthetic sequences of earthquakes.  Each sequence is composed of 20,000 events  M >= 5.0.  Each earthquake is separated from the previous earthquake by the amount of time necessary to build up sufficient strain for an earthquake of that size. The maximum size of earthquakes in the sequences are set to correspond to 15 m of slip on the fault.\n",
      "\n",
      "500 sequences are generated for each fault, with variable fault dip and slip rate (called Ddot from $\\dot{D}$ after fault slip $D$).  In each iteration, dip and Ddot are sampled from uniform distributions based on geologic and geodetic infomation.  This is to ensure that uncertainty in these critical parameters is incorporated into the final probability distributions.\n",
      "\n",
      "Then, the probability of observing an earthquake above a magnitude $M_{min}$ in an observation window of time $t$ (which is in contiguous years) is calculated by running a rolling maximum function of length $t$ over the earthquake time series (including interseismic years), and counting what fraction of time windows contain a large enough earthquake out of the total number of time windows."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All work here is done in Python.  The code snippets below are a complete and functional version of the Python script used to do the calculations; however, a supplementary Python module called 'eq_stats' was made."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Setting up the problem"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Import necessary modules"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('../eq_stats')\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import eq_stats as eqs\n",
      "import time\n",
      "from joblib import Parallel, delayed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Read in fault data table\n",
      "\n",
      "Makes a Pandas dataframe of fault data (length, slip rates, etc.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = pd.read_csv('../data/lanf_stats.csv', index_col=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Define some variables to be used later"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_eq_samp = 2e4 # number of earthquakes in time series\n",
      "time_window = np.hstack( (1, np.arange(5, 105, step=5) ) ) # observation times\n",
      "mc_iters = 5e2 # number of Monte Carlo iterations\n",
      "mc_index = np.arange(mc_iters, dtype='int')\n",
      "mc_cols = ['dip', 'Ddot'] + [t for t in time_window]\n",
      "max_eq_slip = 15 #m\n",
      "Mc = 7.64 # Hypothetical corner magnitude for Continental Rift Boundaries"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Make list of minimum search magnitude $M_{min}$, and then make MultiIndex for Pandas dataframes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min_M_list = [5, 5.5, 6, 6.5, 7, 7.5]\n",
      "\n",
      "df_ind_tuples = [[i, M] for i in mc_index for M in min_M_list]\n",
      "df_multi_ind = pd.MultiIndex.from_tuples(df_ind_tuples, names=['mc_iter','M'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Define a function for Joblib Parallel to calculate probabilities for each iteration.\n",
      "\n",
      "Function is defined here so it can access all variables generated by script, not just passed variables.  This makes the code cleaner even if it's not very abstracted.\n",
      "\n",
      "Here is what this function does:\n",
      "\n",
      "- Get the dip, Ddot and maximum earthquake magnitude for each iteration.\n",
      "- Take this info and make the earthquake sequence:\n",
      "    - Take the max earthquake magnitude and make a frequency-magnitude distribution based on a Gutenburg-Richter exponential model.\n",
      "    - Take 50k samples from this distribution, \n",
      "- Make an earthquake time series form the EQ sequence\n",
      "    - Calculate the interseismic strain accumulation time for each event\n",
      "    - Separate each earthquake in the sequence with the appropriate number of years with no events.\n",
      "- Calculate the probability of observation\n",
      "    - Run a rolling maximum for each $t$ in [1, 5, 10, 15, ..., 95, 100]\n",
      "    - Calculate the observation probability above $M_{min}$ in [5, 5.5, 6, 6.5, 7, 7.5]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calc_iter_probs(iter):\n",
      "    df_iter = fdf.loc[iter].copy()\n",
      "    df_iter['dip'] = mc_d['dip_samp'][iter]\n",
      "    df_iter['Ddot'] = mc_d['Ddot_samp'][iter]\n",
      "\n",
      "    # Generate EQ sample/sequence from F(M) dist.\n",
      "    m_vec = np.linspace(5, mc_d['max_M'][iter], num=1000)\n",
      "    fm_vec = eqs.F(m_vec, Mc=Mc)\n",
      "    M_samp = eqs.sample_from_pdf(m_vec, fm_vec, n_eq_samp)\n",
      "    Mo_samp = eqs.calc_Mo_from_M(M_samp)\n",
      "    \n",
      "    # Make time series of earthquakes, including no eq years\n",
      "    recur_int = eqs.calc_recurrence_interval(Mo=Mo_samp, \n",
      "                                             dip=mc_d['dip_samp'][iter],\n",
      "                                             slip_rate=mc_d['Ddot_samp'][iter],\n",
      "                                             L=params['L_km'],\n",
      "                                             z=params['z_km'])\n",
      "\n",
      "    cum_yrs = eqs.calc_cumulative_yrs(recur_int)\n",
      "    eq_series = eqs.make_eq_time_series(M_samp, cum_yrs)\n",
      "    \n",
      "    # calculate probability of observing EQ in time_window\n",
      "    for t in time_window:\n",
      "        roll_max = pd.rolling_max(eq_series, t)\n",
      "        df_iter[t] = eqs.get_probability_above_value(roll_max, min_M_list)\n",
      "\n",
      "    return df_iter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Iterate through the faults in the fault database, doing all the calculations for each.\n",
      "\n",
      "The setup of this for loop is basically this:\n",
      "\n",
      "- Make DataFrame for each fault.\n",
      "    - Columns are dip, Ddot, and observation time windows.\n",
      "    - Rows are values for each Monte Carlo iteration.  Values for time windows are calculated probabilities.\n",
      "    \n",
      "- Calculate maximum earthquake magnitude for each MC iteration.\n",
      "\n",
      "- Run the above 'calc_iter_probs' function (parallelized over the MC iterations) and concatenate the results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for fault in list(f.index):\n",
      "    fdf = pd.DataFrame(index=df_multi_ind, columns=mc_cols, dtype='float')\n",
      "    params = f.loc[fault]\n",
      "    mc_d = {}\n",
      "    mc_d['dip_samp'], mc_d['dip_frac'] = eqs.dip_rand_samp( params['dip_deg'], \n",
      "                                                         params['dip_err_deg'], \n",
      "                                                         mc_iters)\n",
      "\n",
      "    mc_d['Ddot_samp'] = eqs.Ddot_rand_samp(params['slip_rate_mm_a'],\n",
      "                                           params['sr_err_mm_a'], mc_iters)\n",
      "\n",
      "    mc_d['max_Mo'] = eqs.calc_Mo_from_fault_params(L=params['L_km'], \n",
      "                                                   z=params['z_km'], \n",
      "                                                   dip=mc_d['dip_samp'], \n",
      "                                                   D=max_eq_slip)\n",
      "\n",
      "    mc_d['max_M'] = eqs.calc_M_from_Mo(mc_d['max_Mo'])\n",
      "\n",
      "    t0 = time.time()\n",
      "    prob_list = Parallel(n_jobs=-2)( delayed( calc_iter_probs)(ii) \n",
      "                                    for ii in mc_index)\n",
      "    print 'done with parallel calcs in {} s'.format( (time.time()-t0) )\n",
      "    for ii in mc_index:\n",
      "        fdf.loc[ii][:] = prob_list[ii]\n",
      "    fdf.to_csv('../results/{}_all_M.csv'.format(fault))\n",
      "\n",
      "    print 'done with {}'.format(fault)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}